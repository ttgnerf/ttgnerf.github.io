
<!DOCTYPE html>
<html>

<head lang="en">

<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Training and Tuning Generative Neural Radiance Fields for Attribute-Conditional 3D-Aware Face Generation
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <h3 class="col-md-12 text-center">
                        submission to TOG
                    </h3>
                </ul>
            </div>
        </div>


<!--        <div class="row">-->
<!--                <div class="col-md-4 col-md-offset-4 text-center">-->
<!--                    <ul class="nav nav-pills nav-justified">-->
<!--                        <li>-->
<!--                            <a href="https://arxiv.org/abs/2208.12550">-->
<!--                            <image src="img/paper_image.png" height="60px">-->
<!--                                <h4><strong>Paper</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="https://youtu.be/EpH175">-->
<!--                            <image src="img/youtube_icon.png" height="60px">-->
<!--                                <h4><strong>Video</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                        <li>-->
<!--                            <a href="https://github.com/zhangqianhui/TT-GNeRF">-->
<!--                            <image src="img/github.png" height="60px">-->
<!--                                <h4><strong>Code</strong></h4>-->
<!--                            </a>-->
<!--                        </li>-->
<!--                    </ul>-->
<!--                </div>-->
<!--        </div>-->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="img/teaser_opti.gif" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
Generative Neural Radiance Fields (GNeRF) based 3D-aware GANs have demonstrated remarkable capabilities in generating high-quality images while maintaining strong 3D consistency. Notably, significant advancements have been made in the domain of face generation. However, most existing models prioritize view consistency over disentanglement, resulting in limited semantic/attribute control during generation. To address this limitation, we propose a conditional GNeRF model that incorporates specific attribute labels as input to enhance the controllability and disentanglement abilities of 3D-aware generative models. Our approach builds upon a pre-trained 3D-aware model and integrates a Dual-Branches Attribute-Editing Module (DAEM) to enable attribute-based generation control. Furthermore, we introduce a Training as Init and Optimizing for Tuning (TRIOT) method to optimize the latent vector and further improve attribute-editing precision. Our extensive experiments demonstrate that our model produces high-quality edits with superior view consistency while preserving non-target regions.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="./img/demo.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Double-branch Attribute Editing
                </h3>
                <p class="text-justify">
                     We propose a dual branches attribute-editing module (DAEM) to promote the controllability and disentanglement of the 3D-aware generative model.
                </p>
                <p style="text-align:center;">
                    <image src="img/DAEM.png" height="100px" class="img-responsive">
                </p>

            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Triot: Training-as-Init, Optimizing-for-Tuning
                </h3>
                <p class="text-justify">
                    We present a novel learning method, `Training-as-Init, Optimizing-for-Tuning' (Triot), combining the model-training and latent-optimizing method for the attribute-editing task.
                </p>
                <p style="text-align:center;">
                    <image src="img/Triot.png" class="img-responsive" alt="scales">
                </p>
                <p class="text-justify">
                     In detail, we take the edited latent vector for target attributes as init, fix the entire model, then optimize the latent vector with the proposed consistency losses to search for better latent code.
                </p>
            </div>
        </div>

    </div>
</body>
</html>
